{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkIN_I7Liked",
        "outputId": "fbf845d5-93b6-4fd7-cf84-9d5586209d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "Training samples: 721\n",
            "Testing samples: 309\n",
            "Features: 8\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT 1: ANN Architecture Investigation\n",
            "============================================================\n",
            "\n",
            "Testing architecture: 8-5-1 (ReLU)\n",
            "  Run 1/10: Test MAE = 0.6704\n",
            "  Run 2/10: Test MAE = 0.6094\n",
            "  Run 3/10: Test MAE = 0.5896\n",
            "  Run 4/10: Test MAE = 0.6007\n",
            "  Run 5/10: Test MAE = 0.6584\n",
            "  Run 6/10: Test MAE = 0.6400\n",
            "  Run 7/10: Test MAE = 0.5988\n",
            "  Run 8/10: Test MAE = 0.6475\n",
            "  Run 9/10: Test MAE = 0.6089\n",
            "  Run 10/10: Test MAE = 0.6249\n",
            "  Average Test MAE: 0.6248 ± 0.0263\n",
            "\n",
            "Testing architecture: 8-10-1 (ReLU)\n",
            "  Run 1/10: Test MAE = 0.8431\n",
            "  Run 2/10: Test MAE = 1.1763\n",
            "  Run 3/10: Test MAE = 1.2007\n",
            "  Run 4/10: Test MAE = 1.0736\n",
            "  Run 5/10: Test MAE = 1.0971\n",
            "  Run 6/10: Test MAE = 1.1583\n",
            "  Run 7/10: Test MAE = 1.0041\n",
            "  Run 8/10: Test MAE = 0.8901\n",
            "  Run 9/10: Test MAE = 0.9761\n",
            "  Run 10/10: Test MAE = 0.7825\n",
            "  Average Test MAE: 1.0202 ± 0.1385\n",
            "\n",
            "Testing architecture: 8-20-1 (ReLU)\n",
            "  Run 1/10: Test MAE = 1.7288\n",
            "  Run 2/10: Test MAE = 1.9629\n",
            "  Run 3/10: Test MAE = 2.0758\n",
            "  Run 4/10: Test MAE = 1.9404\n",
            "  Run 5/10: Test MAE = 2.3383\n",
            "  Run 6/10: Test MAE = 2.2128\n",
            "  Run 7/10: Test MAE = 1.6814\n",
            "  Run 8/10: Test MAE = 1.8272\n",
            "  Run 9/10: Test MAE = 1.7578\n",
            "  Run 10/10: Test MAE = 1.9000\n",
            "  Average Test MAE: 1.9425 ± 0.2028\n",
            "\n",
            "Testing architecture: 8-10-5-1 (ReLU-ReLU)\n",
            "  Run 1/10: Test MAE = 0.7020\n",
            "  Run 2/10: Test MAE = 0.7445\n",
            "  Run 3/10: Test MAE = 0.7778\n",
            "  Run 4/10: Test MAE = 0.6561\n",
            "  Run 5/10: Test MAE = 0.7047\n",
            "  Run 6/10: Test MAE = 0.7379\n",
            "  Run 7/10: Test MAE = 0.8085\n",
            "  Run 8/10: Test MAE = 0.7134\n",
            "  Run 9/10: Test MAE = 0.7117\n",
            "  Run 10/10: Test MAE = 0.7125\n",
            "  Average Test MAE: 0.7269 ± 0.0405\n",
            "\n",
            "Testing architecture: 8-10-1 (Tanh)\n",
            "  Run 1/10: Test MAE = 0.6139\n",
            "  Run 2/10: Test MAE = 0.6803\n",
            "  Run 3/10: Test MAE = 0.7864\n",
            "  Run 4/10: Test MAE = 0.6800\n",
            "  Run 5/10: Test MAE = 0.6653\n",
            "  Run 6/10: Test MAE = 0.6940\n",
            "  Run 7/10: Test MAE = 0.7767\n",
            "  Run 8/10: Test MAE = 0.7573\n",
            "  Run 9/10: Test MAE = 0.8417\n",
            "  Run 10/10: Test MAE = 0.7468\n",
            "  Average Test MAE: 0.7242 ± 0.0652\n",
            "\n",
            "Testing architecture: 8-10-1 (Logistic)\n",
            "  Run 1/10: Test MAE = 0.5294\n",
            "  Run 2/10: Test MAE = 0.5038\n",
            "  Run 3/10: Test MAE = 0.5267\n",
            "  Run 4/10: Test MAE = 0.6276\n",
            "  Run 5/10: Test MAE = 0.5495\n",
            "  Run 6/10: Test MAE = 0.6232\n",
            "  Run 7/10: Test MAE = 0.5251\n",
            "  Run 8/10: Test MAE = 0.5613\n",
            "  Run 9/10: Test MAE = 0.5840\n",
            "  Run 10/10: Test MAE = 0.5998\n",
            "  Average Test MAE: 0.5630 ± 0.0414\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT 2: Swarm Size vs Iterations (Budget=500)\n",
            "============================================================\n",
            "\n",
            "Testing allocation: 10x50 (swarm=10, iter=50)\n",
            "  Run 1/10: Test MAE = 1.1806\n",
            "  Run 2/10: Test MAE = 1.4332\n",
            "  Run 3/10: Test MAE = 1.0608\n",
            "  Run 4/10: Test MAE = 0.8087\n",
            "  Run 5/10: Test MAE = 1.0362\n",
            "  Run 6/10: Test MAE = 1.1276\n",
            "  Run 7/10: Test MAE = 1.1159\n",
            "  Run 8/10: Test MAE = 1.0877\n",
            "  Run 9/10: Test MAE = 1.3940\n",
            "  Run 10/10: Test MAE = 0.8828\n",
            "  Average Test MAE: 1.1128 ± 0.1847\n",
            "\n",
            "Testing allocation: 25x20 (swarm=25, iter=20)\n",
            "  Run 1/10: Test MAE = 1.0504\n",
            "  Run 2/10: Test MAE = 1.4080\n",
            "  Run 3/10: Test MAE = 1.4467\n",
            "  Run 4/10: Test MAE = 1.5281\n",
            "  Run 5/10: Test MAE = 1.9247\n",
            "  Run 6/10: Test MAE = 1.4575\n",
            "  Run 7/10: Test MAE = 1.2799\n",
            "  Run 8/10: Test MAE = 1.9195\n",
            "  Run 9/10: Test MAE = 1.2784\n",
            "  Run 10/10: Test MAE = 1.4109\n",
            "  Average Test MAE: 1.4704 ± 0.2587\n",
            "\n",
            "Testing allocation: 50x10 (swarm=50, iter=10)\n",
            "  Run 1/10: Test MAE = 2.1050\n",
            "  Run 2/10: Test MAE = 1.7398\n",
            "  Run 3/10: Test MAE = 1.8022\n",
            "  Run 4/10: Test MAE = 2.3585\n",
            "  Run 5/10: Test MAE = 1.9133\n",
            "  Run 6/10: Test MAE = 1.7956\n",
            "  Run 7/10: Test MAE = 1.5910\n",
            "  Run 8/10: Test MAE = 1.7877\n",
            "  Run 9/10: Test MAE = 1.7383\n",
            "  Run 10/10: Test MAE = 1.6929\n",
            "  Average Test MAE: 1.8524 ± 0.2129\n",
            "\n",
            "Testing allocation: 100x5 (swarm=100, iter=5)\n",
            "  Run 1/10: Test MAE = 1.7901\n",
            "  Run 2/10: Test MAE = 1.7044\n",
            "  Run 3/10: Test MAE = 2.1136\n",
            "  Run 4/10: Test MAE = 1.6310\n",
            "  Run 5/10: Test MAE = 1.6981\n",
            "  Run 6/10: Test MAE = 1.9114\n",
            "  Run 7/10: Test MAE = 1.6598\n",
            "  Run 8/10: Test MAE = 1.7486\n",
            "  Run 9/10: Test MAE = 1.7478\n",
            "  Run 10/10: Test MAE = 1.8331\n",
            "  Average Test MAE: 1.7838 ± 0.1351\n",
            "\n",
            "============================================================\n",
            "EXPERIMENT 3: PSO Acceleration Coefficients\n",
            "============================================================\n",
            "\n",
            "Testing: Standard (w=0.729, c1=c2=1.49)\n",
            "  Run 1/10: Test MAE = 1.0907\n",
            "  Run 2/10: Test MAE = 1.1428\n",
            "  Run 3/10: Test MAE = 1.0223\n",
            "  Run 4/10: Test MAE = 1.3327\n",
            "  Run 5/10: Test MAE = 1.1539\n",
            "  Run 6/10: Test MAE = 0.9466\n",
            "  Run 7/10: Test MAE = 0.9403\n",
            "  Run 8/10: Test MAE = 1.1387\n",
            "  Run 9/10: Test MAE = 1.0816\n",
            "  Run 10/10: Test MAE = 1.0967\n",
            "  Average Test MAE: 1.0946 ± 0.1075\n",
            "\n",
            "Testing: High acceleration (w=0.5, c1=c2=2.0)\n",
            "  Run 1/10: Test MAE = 0.8292\n",
            "  Run 2/10: Test MAE = 0.8980\n",
            "  Run 3/10: Test MAE = 0.9501\n",
            "  Run 4/10: Test MAE = 1.3095\n",
            "  Run 5/10: Test MAE = 1.1854\n",
            "  Run 6/10: Test MAE = 1.1824\n",
            "  Run 7/10: Test MAE = 0.8550\n",
            "  Run 8/10: Test MAE = 1.0050\n",
            "  Run 9/10: Test MAE = 1.1277\n",
            "  Run 10/10: Test MAE = 1.2679\n",
            "  Average Test MAE: 1.0610 ± 0.1666\n",
            "\n",
            "Testing: Cognitive-heavy (w=0.9, c1=2.0, c2=0.5)\n",
            "  Run 1/10: Test MAE = 1.3471\n",
            "  Run 2/10: Test MAE = 0.9463\n",
            "  Run 3/10: Test MAE = 1.0218\n",
            "  Run 4/10: Test MAE = 0.8137\n",
            "  Run 5/10: Test MAE = 1.0456\n",
            "  Run 6/10: Test MAE = 1.2673\n",
            "  Run 7/10: Test MAE = 1.3807\n",
            "  Run 8/10: Test MAE = 1.2132\n",
            "  Run 9/10: Test MAE = 0.9138\n",
            "  Run 10/10: Test MAE = 1.0603\n",
            "  Average Test MAE: 1.1010 ± 0.1821\n",
            "\n",
            "Testing: Social-heavy (w=0.9, c1=0.5, c2=2.0)\n",
            "  Run 1/10: Test MAE = 1.7750\n",
            "  Run 2/10: Test MAE = 1.9439\n",
            "  Run 3/10: Test MAE = 1.4929\n",
            "  Run 4/10: Test MAE = 2.0961\n",
            "  Run 5/10: Test MAE = 1.9341\n",
            "  Run 6/10: Test MAE = 1.7724\n",
            "  Run 7/10: Test MAE = 1.5570\n",
            "  Run 8/10: Test MAE = 1.4812\n",
            "  Run 9/10: Test MAE = 1.5560\n",
            "  Run 10/10: Test MAE = 1.8672\n",
            "  Average Test MAE: 1.7476 ± 0.2048\n",
            "\n",
            "Testing: Low inertia (w=0.4, c1=c2=1.0)\n",
            "  Run 1/10: Test MAE = 0.6750\n",
            "  Run 2/10: Test MAE = 0.5518\n",
            "  Run 3/10: Test MAE = 0.5974\n",
            "  Run 4/10: Test MAE = 0.5321\n",
            "  Run 5/10: Test MAE = 0.6323\n",
            "  Run 6/10: Test MAE = 0.6775\n",
            "  Run 7/10: Test MAE = 0.5381\n",
            "  Run 8/10: Test MAE = 0.6224\n",
            "  Run 9/10: Test MAE = 0.6471\n",
            "  Run 10/10: Test MAE = 0.6841\n",
            "  Average Test MAE: 0.6158 ± 0.0554\n",
            "\n",
            "Results saved to experiment_results.json\n",
            "\n",
            "============================================================\n",
            "ALL EXPERIMENTS COMPLETED\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "class ANN:\n",
        "    \"\"\"\n",
        "    Feedforward Artificial Neural Network with configurable architecture.\n",
        "    Implements multiple activation functions for regression tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes, activation_functions):\n",
        "        \"\"\"\n",
        "        Initialize ANN with specified architecture.\n",
        "\n",
        "        Args:\n",
        "            layer_sizes: List of integers specifying neurons in each layer\n",
        "                        e.g., [8, 10, 5, 1] for 8 inputs, 2 hidden layers, 1 output\n",
        "            activation_functions: List of activation function names for each layer\n",
        "                                 e.g., ['relu', 'relu', 'linear']\n",
        "        \"\"\"\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.num_layers = len(layer_sizes)\n",
        "        self.activation_functions = activation_functions\n",
        "\n",
        "        # Initialize weights and biases randomly\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        # Create weight matrices between consecutive layers\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Xavier initialization for better convergence\n",
        "            limit = np.sqrt(6 / (layer_sizes[i] + layer_sizes[i+1]))\n",
        "            w = np.random.uniform(-limit, limit, (layer_sizes[i], layer_sizes[i+1]))\n",
        "            b = np.zeros((1, layer_sizes[i+1]))\n",
        "            self.weights.append(w)\n",
        "            self.biases.append(b)\n",
        "\n",
        "    def set_parameters(self, params):\n",
        "        \"\"\"\n",
        "        Set network parameters (weights and biases) from a flat vector.\n",
        "        Used by PSO to update the network.\n",
        "\n",
        "        Args:\n",
        "            params: 1D numpy array containing all weights and biases\n",
        "        \"\"\"\n",
        "        idx = 0\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        # Reconstruct weight matrices and bias vectors from flat array\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Calculate size of weight matrix\n",
        "            w_size = self.layer_sizes[i] * self.layer_sizes[i+1]\n",
        "            # Extract and reshape weights\n",
        "            w = params[idx:idx+w_size].reshape(self.layer_sizes[i], self.layer_sizes[i+1])\n",
        "            idx += w_size\n",
        "\n",
        "            # Extract biases\n",
        "            b_size = self.layer_sizes[i+1]\n",
        "            b = params[idx:idx+b_size].reshape(1, self.layer_sizes[i+1])\n",
        "            idx += b_size\n",
        "\n",
        "            self.weights.append(w)\n",
        "            self.biases.append(b)\n",
        "\n",
        "    def get_parameter_count(self):\n",
        "        \"\"\"\n",
        "        Calculate total number of parameters (weights + biases) in the network.\n",
        "\n",
        "        Returns:\n",
        "            Integer count of total parameters\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Weights: input_size * output_size\n",
        "            count += self.layer_sizes[i] * self.layer_sizes[i+1]\n",
        "            # Biases: output_size\n",
        "            count += self.layer_sizes[i+1]\n",
        "        return count\n",
        "\n",
        "    def activate(self, x, function_name):\n",
        "        \"\"\"\n",
        "        Apply activation function to input.\n",
        "\n",
        "        Args:\n",
        "            x: Input array\n",
        "            function_name: Name of activation function (\n",
        "'logistic', 'relu', 'tanh', 'linear')\n",
        "\n",
        "        Returns:\n",
        "            Activated output\n",
        "        \"\"\"\n",
        "        if function_name == 'logistic':\n",
        "            # Logistic sigmoid: 1 / (1 + e^(-x))\n",
        "            return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to prevent overflow\n",
        "        elif function_name == 'relu':\n",
        "            # ReLU: max(0, x)\n",
        "            return np.maximum(0, x)\n",
        "        elif function_name == 'tanh':\n",
        "            # Hyperbolic tangent\n",
        "            return np.tanh(x)\n",
        "        elif function_name == 'linear':\n",
        "            # Linear (no activation)\n",
        "            return x\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown activation function: {function_name}\")\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Perform forward propagation through the network.\n",
        "\n",
        "        Args:\n",
        "            X: Input data, shape (n_samples, n_features)\n",
        "\n",
        "        Returns:\n",
        "            Network output, shape (n_samples, n_outputs)\n",
        "        \"\"\"\n",
        "        activation = X\n",
        "\n",
        "        # Propagate through each layer\n",
        "        for i in range(len(self.weights)):\n",
        "            # Linear transformation: z = activation * weights + bias\n",
        "            z = np.dot(activation, self.weights[i]) + self.biases[i]\n",
        "            # Apply activation function\n",
        "            activation = self.activate(z, self.activation_functions[i])\n",
        "\n",
        "        return activation\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions on input data.\n",
        "\n",
        "        Args:\n",
        "            X: Input data\n",
        "\n",
        "        Returns:\n",
        "            Predictions\n",
        "        \"\"\"\n",
        "        return self.forward(X)\n",
        "\n",
        "class PSO:\n",
        "    \"\"\"\n",
        "    Particle Swarm Optimization implementation following Algorithm 39\n",
        "    from \"Essentials of Metaheuristics\" by Sean Luke.\n",
        "    Uses informants topology rather than global best.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fitness_function, dimensions, bounds,\n",
        "                 swarm_size=30, max_iterations=100,\n",
        "                 num_informants=3, w=0.729, c1=1.49445, c2=1.49445):\n",
        "        \"\"\"\n",
        "        Initialize PSO with specified parameters.\n",
        "\n",
        "        Args:\n",
        "            fitness_function: Function to minimize (lower is better)\n",
        "            dimensions: Number of dimensions in solution space\n",
        "            bounds: Tuple of (min, max) for parameter values\n",
        "            swarm_size: Number of particles in swarm\n",
        "            max_iterations: Maximum number of iterations\n",
        "            num_informants: Number of informants per particle\n",
        "            w: Inertia weight\n",
        "            c1: Cognitive coefficient (personal best influence)\n",
        "            c2: Social coefficient (neighborhood best influence)\n",
        "        \"\"\"\n",
        "        self.fitness_function = fitness_function\n",
        "        self.dimensions = dimensions\n",
        "        self.bounds = bounds\n",
        "        self.swarm_size = swarm_size\n",
        "        self.max_iterations = max_iterations\n",
        "        self.num_informants = num_informants\n",
        "        self.w = w  # Inertia weight\n",
        "        self.c1 = c1  # Cognitive coefficient\n",
        "        self.c2 = c2  # Social coefficient\n",
        "\n",
        "        # For tracking best solution found\n",
        "        self.global_best_position = None\n",
        "        self.global_best_fitness = float('inf')\n",
        "        self.fitness_history = []\n",
        "\n",
        "    def initialize_swarm(self):\n",
        "        \"\"\"\n",
        "        Initialize particle positions and velocities.\n",
        "        Corresponds to lines 1-2 of Algorithm 39.\n",
        "\n",
        "        Returns:\n",
        "            positions: Random initial positions\n",
        "            velocities: Random initial velocities\n",
        "        \"\"\"\n",
        "        # Line 1: Initialize positions uniformly in search space\n",
        "        positions = np.random.uniform(\n",
        "            self.bounds[0],\n",
        "            self.bounds[1],\n",
        "            (self.swarm_size, self.dimensions)\n",
        "        )\n",
        "\n",
        "        # Line 2: Initialize velocities\n",
        "        velocity_range = (self.bounds[1] - self.bounds[0]) * 0.1\n",
        "        velocities = np.random.uniform(\n",
        "            -velocity_range,\n",
        "            velocity_range,\n",
        "            (self.swarm_size, self.dimensions)\n",
        "        )\n",
        "\n",
        "        return positions, velocities\n",
        "\n",
        "    def create_informants(self):\n",
        "        \"\"\"\n",
        "        Create informant topology (ring topology).\n",
        "        Each particle is influenced by k neighbors.\n",
        "        Corresponds to line 3 of Algorithm 39.\n",
        "\n",
        "        Returns:\n",
        "            List of lists, where informants[i] contains indices of particle i's informants\n",
        "        \"\"\"\n",
        "        # Line 3: Assign informants to particles\n",
        "        informants = []\n",
        "        for i in range(self.swarm_size):\n",
        "            # Ring topology: include neighbors on both sides\n",
        "            neighbors = []\n",
        "            for j in range(1, self.num_informants + 1):\n",
        "                left = (i - j) % self.swarm_size\n",
        "                right = (i + j) % self.swarm_size\n",
        "                neighbors.append(left)\n",
        "                if len(neighbors) < self.num_informants:\n",
        "                    neighbors.append(right)\n",
        "            # Include self and limit to num_informants\n",
        "            neighbors = list(set([i] + neighbors[:self.num_informants-1]))\n",
        "            informants.append(neighbors)\n",
        "        return informants\n",
        "\n",
        "    def optimize(self, verbose=True):\n",
        "        \"\"\"\n",
        "        Main PSO optimization loop.\n",
        "        Follows Algorithm 39 from Essentials of Metaheuristics.\n",
        "\n",
        "        Returns:\n",
        "            best_position: Best solution found\n",
        "            best_fitness: Fitness of best solution\n",
        "        \"\"\"\n",
        "        # Lines 1-3: Initialize swarm\n",
        "        positions, velocities = self.initialize_swarm()\n",
        "        informants = self.create_informants()\n",
        "\n",
        "        # Line 4: Initialize personal bests\n",
        "        personal_best_positions = positions.copy()\n",
        "        personal_best_fitness = np.array([self.fitness_function(p) for p in positions])\n",
        "\n",
        "        # Initialize neighborhood bests\n",
        "        neighborhood_best_positions = np.zeros_like(positions)\n",
        "        neighborhood_best_fitness = np.full(self.swarm_size, float('inf'))\n",
        "\n",
        "        # Track global best\n",
        "        best_idx = np.argmin(personal_best_fitness)\n",
        "        self.global_best_position = personal_best_positions[best_idx].copy()\n",
        "        self.global_best_fitness = personal_best_fitness[best_idx]\n",
        "\n",
        "        # Line 5: Main loop\n",
        "        for iteration in range(self.max_iterations):\n",
        "\n",
        "            # Update neighborhood bests for each particle\n",
        "            for i in range(self.swarm_size):\n",
        "                # Find best among informants\n",
        "                informant_fitness = [personal_best_fitness[j] for j in informants[i]]\n",
        "                best_informant_idx = informants[i][np.argmin(informant_fitness)]\n",
        "                neighborhood_best_positions[i] = personal_best_positions[best_informant_idx]\n",
        "                neighborhood_best_fitness[i] = personal_best_fitness[best_informant_idx]\n",
        "\n",
        "            # Update each particle\n",
        "            for i in range(self.swarm_size):\n",
        "\n",
        "                # Line 6: Generate random values\n",
        "                rp = np.random.uniform(0, 1, self.dimensions)\n",
        "                rg = np.random.uniform(0, 1, self.dimensions)\n",
        "\n",
        "                # Line 7: Update velocity\n",
        "                # v_i = w * v_i + c1 * rp * (p_i - x_i) + c2 * rg * (n_i - x_i)\n",
        "                cognitive = self.c1 * rp * (personal_best_positions[i] - positions[i])\n",
        "                social = self.c2 * rg * (neighborhood_best_positions[i] - positions[i])\n",
        "                velocities[i] = self.w * velocities[i] + cognitive + social\n",
        "\n",
        "                # Line 8: Update position\n",
        "                positions[i] = positions[i] + velocities[i]\n",
        "\n",
        "                # Line 9: Enforce bounds (clamping strategy)\n",
        "                positions[i] = np.clip(positions[i], self.bounds[0], self.bounds[1])\n",
        "\n",
        "                # Line 10: Evaluate fitness\n",
        "                fitness = self.fitness_function(positions[i])\n",
        "\n",
        "                # Line 11: Update personal best\n",
        "                if fitness < personal_best_fitness[i]:\n",
        "                    personal_best_positions[i] = positions[i].copy()\n",
        "                    personal_best_fitness[i] = fitness\n",
        "\n",
        "                    # Update global best if necessary\n",
        "                    if fitness < self.global_best_fitness:\n",
        "                        self.global_best_position = positions[i].copy()\n",
        "                        self.global_best_fitness = fitness\n",
        "\n",
        "            # Store best fitness for this iteration\n",
        "            self.fitness_history.append(self.global_best_fitness)\n",
        "\n",
        "            if verbose and (iteration + 1) % 10 == 0:\n",
        "                print(f\"Iteration {iteration + 1}/{self.max_iterations}, \"\n",
        "                      f\"Best Fitness: {self.global_best_fitness:.4f}\")\n",
        "\n",
        "        return self.global_best_position, self.global_best_fitness\n",
        "\n",
        "def load_and_preprocess_data(filepath='/concrete_data.csv'):\n",
        "    \"\"\"\n",
        "    Load and preprocess the concrete strength dataset.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to CSV file\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_test, y_train, y_test, scaler_X, scaler_y\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    data = pd.read_csv(filepath)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.iloc[:, :-1].values  # First 8 columns are features\n",
        "    y = data.iloc[:, -1].values.reshape(-1, 1)  # Last column is target\n",
        "\n",
        "    # Split into training (70%) and testing (30%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42\n",
        "    )\n",
        "\n",
        "    # Normalize features and target for better ANN performance\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "\n",
        "    X_train = scaler_X.fit_transform(X_train)\n",
        "    X_test = scaler_X.transform(X_test)\n",
        "    y_train = scaler_y.fit_transform(y_train)\n",
        "    y_test = scaler_y.transform(y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y\n",
        "\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate Mean Absolute Error.\n",
        "\n",
        "    Args:\n",
        "        y_true: True values\n",
        "        y_pred: Predicted values\n",
        "\n",
        "    Returns:\n",
        "        MAE value\n",
        "    \"\"\"\n",
        "    return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "\n",
        "def create_fitness_function(ann, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Create fitness function for PSO that evaluates ANN performance.\n",
        "    Couples PSO and ANN together.\n",
        "\n",
        "    Args:\n",
        "        ann: ANN instance\n",
        "        X_train: Training features\n",
        "        y_train: Training targets\n",
        "\n",
        "    Returns:\n",
        "        Fitness function that takes parameter vector and returns MAE\n",
        "    \"\"\"\n",
        "    def fitness(params):\n",
        "        \"\"\"\n",
        "        Fitness function evaluates how well the ANN performs with given parameters.\n",
        "        Lower MAE = better fitness.\n",
        "\n",
        "        Args:\n",
        "            params: Flat vector of ANN weights and biases\n",
        "\n",
        "        Returns:\n",
        "            Mean Absolute Error on training set\n",
        "        \"\"\"\n",
        "        # Set ANN parameters from PSO particle\n",
        "        ann.set_parameters(params)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = ann.predict(X_train)\n",
        "\n",
        "        # Calculate and return error (fitness to minimize)\n",
        "        mae = mean_absolute_error(y_train, predictions)\n",
        "        return mae\n",
        "\n",
        "    return fitness\n",
        "\n",
        "\n",
        "def evaluate_ann(ann, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluate trained ANN on test set.\n",
        "\n",
        "    Args:\n",
        "        ann: Trained ANN\n",
        "        X_test: Test features\n",
        "        y_test: Test targets\n",
        "\n",
        "    Returns:\n",
        "        Test MAE\n",
        "    \"\"\"\n",
        "    predictions = ann.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    return mae\n",
        "\n",
        "\n",
        "def run_single_experiment(layer_sizes, activations, swarm_size, max_iterations,\n",
        "                         w, c1, c2, num_informants, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Run a single PSO-ANN experiment.\n",
        "\n",
        "    Args:\n",
        "        layer_sizes: ANN architecture\n",
        "        activations: Activation functions for each layer\n",
        "        swarm_size: PSO swarm size\n",
        "        max_iterations: PSO iterations\n",
        "        w, c1, c2: PSO coefficients\n",
        "        num_informants: Number of informants\n",
        "        X_train, y_train: Training data\n",
        "        X_test, y_test: Test data\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results\n",
        "    \"\"\"\n",
        "    # Create ANN\n",
        "    ann = ANN(layer_sizes, activations)\n",
        "\n",
        "    # Get parameter count and bounds\n",
        "    param_count = ann.get_parameter_count()\n",
        "    bounds = (-2, 2)  # Typical range for neural network weights\n",
        "\n",
        "    # Create fitness function\n",
        "    fitness_func = create_fitness_function(ann, X_train, y_train)\n",
        "\n",
        "    # Initialize PSO\n",
        "    pso = PSO(\n",
        "        fitness_function=fitness_func,\n",
        "        dimensions=param_count,\n",
        "        bounds=bounds,\n",
        "        swarm_size=swarm_size,\n",
        "        max_iterations=max_iterations,\n",
        "        num_informants=num_informants,\n",
        "        w=w,\n",
        "        c1=c1,\n",
        "        c2=c2\n",
        "    )\n",
        "\n",
        "    # Run optimization\n",
        "    best_params, train_mae = pso.optimize(verbose=False)\n",
        "\n",
        "    # Set best parameters and evaluate on test set\n",
        "    ann.set_parameters(best_params)\n",
        "    test_mae = evaluate_ann(ann, X_test, y_test)\n",
        "\n",
        "    return {\n",
        "        'train_mae': train_mae,\n",
        "        'test_mae': test_mae,\n",
        "        'fitness_history': pso.fitness_history\n",
        "    }\n",
        "\n",
        "\n",
        "def experiment_architecture(X_train, y_train, X_test, y_test, num_runs=10):\n",
        "    \"\"\"\n",
        "    Experiment 1: Test different ANN architectures.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPERIMENT 1: ANN Architecture Investigation\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Different architectures to test\n",
        "    architectures = [\n",
        "        ([8, 5, 1], ['relu', 'linear'], '8-5-1 (ReLU)'),\n",
        "        ([8, 10, 1], ['relu', 'linear'], '8-10-1 (ReLU)'),\n",
        "        ([8, 20, 1], ['relu', 'linear'], '8-20-1 (ReLU)'),\n",
        "        ([8, 10, 5, 1], ['relu', 'relu', 'linear'], '8-10-5-1 (ReLU-ReLU)'),\n",
        "        ([8, 10, 1], ['tanh', 'linear'], '8-10-1 (Tanh)'),\n",
        "        ([8, 10, 1], ['logistic', 'linear'], '8-10-1 (Logistic)'),\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for layers, activations, name in architectures:\n",
        "        print(f\"\\nTesting architecture: {name}\")\n",
        "        train_maes = []\n",
        "        test_maes = []\n",
        "\n",
        "        for run in range(num_runs):\n",
        "            result = run_single_experiment(\n",
        "                layer_sizes=layers,\n",
        "                activations=activations,\n",
        "                swarm_size=30,\n",
        "                max_iterations=50,\n",
        "                w=0.729,\n",
        "                c1=1.49445,\n",
        "                c2=1.49445,\n",
        "                num_informants=3,\n",
        "                X_train=X_train,\n",
        "                y_train=y_train,\n",
        "                X_test=X_test,\n",
        "                y_test=y_test\n",
        "            )\n",
        "            train_maes.append(result['train_mae'])\n",
        "            test_maes.append(result['test_mae'])\n",
        "            print(f\"  Run {run+1}/{num_runs}: Test MAE = {result['test_mae']:.4f}\")\n",
        "\n",
        "        results[name] = {\n",
        "            'train_mae_mean': np.mean(train_maes),\n",
        "            'train_mae_std': np.std(train_maes),\n",
        "            'test_mae_mean': np.mean(test_maes),\n",
        "            'test_mae_std': np.std(test_maes)\n",
        "        }\n",
        "\n",
        "        print(f\"  Average Test MAE: {results[name]['test_mae_mean']:.4f} \\u00b1 {results[name]['test_mae_std']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def experiment_swarm_allocation(X_train, y_train, X_test, y_test, num_runs=10):\n",
        "    \"\"\"\n",
        "    Experiment 2: Test different swarm size vs iterations allocations.\n",
        "    Fixed budget of 500 evaluations.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPERIMENT 2: Swarm Size vs Iterations (Budget=500)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Different allocations with budget of 500\n",
        "    allocations = [\n",
        "        (10, 50, '10x50'),\n",
        "        (25, 20, '25x20'),\n",
        "        (50, 10, '50x10'),\n",
        "        (100, 5, '100x5'),\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for swarm_size, iterations, name in allocations:\n",
        "        print(f\"\\nTesting allocation: {name} (swarm={swarm_size}, iter={iterations})\")\n",
        "        train_maes = []\n",
        "        test_maes = []\n",
        "\n",
        "        for run in range(num_runs):\n",
        "            result = run_single_experiment(\n",
        "                layer_sizes=[8, 10, 1],\n",
        "                activations=['relu', 'linear'],\n",
        "                swarm_size=swarm_size,\n",
        "                max_iterations=iterations,\n",
        "                w=0.729,\n",
        "                c1=1.49445,\n",
        "                c2=1.49445,\n",
        "                num_informants=3,\n",
        "                X_train=X_train,\n",
        "                y_train=y_train,\n",
        "                X_test=X_test,\n",
        "                y_test=y_test\n",
        "            )\n",
        "            train_maes.append(result['train_mae'])\n",
        "            test_maes.append(result['test_mae'])\n",
        "            print(f\"  Run {run+1}/{num_runs}: Test MAE = {result['test_mae']:.4f}\")\n",
        "\n",
        "        results[name] = {\n",
        "            'train_mae_mean': np.mean(train_maes),\n",
        "            'train_mae_std': np.std(train_maes),\n",
        "            'test_mae_mean': np.mean(test_maes),\n",
        "            'test_mae_std': np.std(test_maes)\n",
        "        }\n",
        "\n",
        "        print(f\"  Average Test MAE: {results[name]['test_mae_mean']:.4f} \\u00b1 {results[name]['test_mae_std']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def experiment_coefficients(X_train, y_train, X_test, y_test, num_runs=10):\n",
        "    \"\"\"\n",
        "    Experiment 3: Test different PSO acceleration coefficients.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPERIMENT 3: PSO Acceleration Coefficients\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Different coefficient combinations\n",
        "    coefficient_sets = [\n",
        "        (0.729, 1.49445, 1.49445, 'Standard (w=0.729, c1=c2=1.49)'),\n",
        "        (0.5, 2.0, 2.0, 'High acceleration (w=0.5, c1=c2=2.0)'),\n",
        "        (0.9, 2.0, 0.5, 'Cognitive-heavy (w=0.9, c1=2.0, c2=0.5)'),\n",
        "        (0.9, 0.5, 2.0, 'Social-heavy (w=0.9, c1=0.5, c2=2.0)'),\n",
        "        (0.4, 1.0, 1.0, 'Low inertia (w=0.4, c1=c2=1.0)'),\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for w, c1, c2, name in coefficient_sets:\n",
        "        print(f\"\\nTesting: {name}\")\n",
        "        train_maes = []\n",
        "        test_maes = []\n",
        "\n",
        "        for run in range(num_runs):\n",
        "            result = run_single_experiment(\n",
        "                layer_sizes=[8, 10, 1],\n",
        "                activations=['relu', 'linear'],\n",
        "                swarm_size=30,\n",
        "                max_iterations=50,\n",
        "                w=w,\n",
        "                c1=c1,\n",
        "                c2=c2,\n",
        "                num_informants=3,\n",
        "                X_train=X_train,\n",
        "                y_train=y_train,\n",
        "                X_test=X_test,\n",
        "                y_test=y_test\n",
        "            )\n",
        "            train_maes.append(result['train_mae'])\n",
        "            test_maes.append(result['test_mae'])\n",
        "            print(f\"  Run {run+1}/{num_runs}: Test MAE = {result['test_mae']:.4f}\")\n",
        "\n",
        "        results[name] = {\n",
        "            'train_mae_mean': np.mean(train_maes),\n",
        "            'train_mae_std': np.std(train_maes),\n",
        "            'test_mae_mean': np.mean(test_maes),\n",
        "            'test_mae_std': np.std(test_maes)\n",
        "        }\n",
        "\n",
        "        print(f\"  Average Test MAE: {results[name]['test_mae_mean']:.4f} \\u00b1 {results[name]['test_mae_std']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def save_results(results, filename):\n",
        "    \"\"\"Save results to JSON file.\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"\\nResults saved to {filename}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function.\n",
        "    \"\"\"\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    X_train, X_test, y_train, y_test, scaler_X, scaler_y = load_and_preprocess_data()\n",
        "\n",
        "    print(f\"Training samples: {X_train.shape[0]}\")\n",
        "    print(f\"Testing samples: {X_test.shape[0]}\")\n",
        "    print(f\"Features: {X_train.shape[1]}\")\n",
        "\n",
        "    # Run experiments\n",
        "    results = {}\n",
        "\n",
        "    # Experiment 1: Architecture\n",
        "    results['architecture'] = experiment_architecture(X_train, y_train, X_test, y_test, num_runs=10)\n",
        "\n",
        "    # Experiment 2: Swarm allocation\n",
        "    results['swarm_allocation'] = experiment_swarm_allocation(X_train, y_train, X_test, y_test, num_runs=10)\n",
        "\n",
        "    # Experiment 3: Coefficients\n",
        "    results['coefficients'] = experiment_coefficients(X_train, y_train, X_test, y_test, num_runs=10)\n",
        "\n",
        "    # Save all results\n",
        "    save_results(results, 'experiment_results.json')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ALL EXPERIMENTS COMPLETED\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b982c29a"
      },
      "source": [
        "### Option 1: Upload `Concrete_Data.csv` directly to Colab\n",
        "\n",
        "To upload the file, click on the folder icon on the left sidebar (File Browser), then click the 'Upload to session storage' icon (looks like a page with an up arrow). Select your `Concrete_Data.csv` file. Once uploaded, it will be in the default working directory, and the existing code should find it.\n",
        "\n",
        "If you do this, you might not need to change the `filepath` argument explicitly if it's in the root directory, but it's good practice to specify it anyway."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe348500"
      },
      "source": [
        "### Option 2: Mount Google Drive and specify the path\n",
        "\n",
        "If your `Concrete_Data.csv` file is in Google Drive, you can mount your Drive and then provide the path to the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "710463c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e801f77d"
      },
      "source": [
        "Once your Drive is mounted, you can find the path to your file. For example, if it's in a folder named `data` in your Drive, the path would be `/content/drive/MyDrive/data/Concrete_Data.csv`.\n",
        "\n",
        "Now, let's modify the `main` function in the existing cell (`NkIN_I7Liked`) to explicitly pass the `filepath` to `load_and_preprocess_data`. **Remember to replace `'your/path/to/Concrete_Data.csv'` with the actual path to your file.**"
      ]
    }
  ]
}